import{_ as s,c as a,o as p,a8 as e}from"./chunks/framework.DDO5B0CJ.js";const n="/vitepress-java/assets/img_5.x1m0HALQ.png",i="/vitepress-java/assets/img_6.BBC6B95P.png",t="/vitepress-java/assets/img_7.DuMnvZaE.png",l="/vitepress-java/assets/img_8.vyrG7oB3.png",o="/vitepress-java/assets/img_9.C6pv7vO3.png",r="/vitepress-java/assets/img_10.BfHc2DZU.png",c="/vitepress-java/assets/img_11.W-kTm9J3.png",m="/vitepress-java/assets/img_12.B60Z7XIO.png",u="/vitepress-java/assets/img_13.cWNlh_2b.png",g="/vitepress-java/assets/img_14.Ba6oooZ0.png",j=JSON.parse('{"title":"关于Kafka 的 consumer 消费者手动提交详解","description":"","frontmatter":{},"headers":[],"relativePath":"kafka-study/2.md","filePath":"kafka-study/2.md"}'),d={name:"kafka-study/2.md"},f=e('<h1 id="关于kafka-的-consumer-消费者手动提交详解" tabindex="-1">关于Kafka 的 consumer 消费者手动提交详解 <a class="header-anchor" href="#关于kafka-的-consumer-消费者手动提交详解" aria-label="Permalink to &quot;关于Kafka 的 consumer 消费者手动提交详解&quot;">​</a></h1><p>但是offset下标自动提交其实在很多场景都不适用，因为自动提交是在kafka拉取到数据之后就直接提交，这样很容易丢失数据，尤其是在需要事物控制的时候。</p><p>很多情况下我们需要从kafka成功拉取数据之后，对数据进行相应的处理之后再进行提交。 如拉取数据之后进行写入mysql这种 ， 所以这时我们就需要进行手动提交kafka的offset下标。</p><blockquote><p>这里顺便说下offset具体是什么。</p></blockquote><p>offset：指的是kafka的topic中的每个消费组消费的下标。</p><p>简单的来说就是一条消息对应一个offset下标，每次消费数据的时候如果提交offset，那么下次消费就会从提交的offset加一那里开始消费。</p><p>比如一个topic中有100条数据，我消费了50条并且提交了，那么此时的kafka服务端记录提交的offset就是49(offset从0开始)，那么下次消费的时候offset就从50开始消费。</p><h2 id="测试" tabindex="-1">测试 <a class="header-anchor" href="#测试" aria-label="Permalink to &quot;测试&quot;">​</a></h2><p>说了这么，那么我们开始进行手动提交测试。</p><p>首先，使用kafka 的producer 程序往kafka集群发送了100条测试数据。</p><p><img src="'+n+'" alt="img_5.png" loading="lazy"></p><p><img src="'+i+`" alt="img_6.png" loading="lazy"></p><p>程序打印中已经成功发送了，这里我们在kafka服务器使用命令中来查看是否成功发送.</p><p>命令如下:</p><div class="language-angular2html vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">angular2html</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span> kafka-console-consumer.sh  --zookeeper master:2181  --topic KAFKA_TEST2 --from-beginning</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><blockquote><p>注:</p></blockquote><p>1.master 是我在linux中做了IP映射的关系，实际可以换成IP。</p><p>2.因为kafka是集群，所以也可以在集群的其他机器进行消费。</p><p>可以看到已经成功发送了100条。</p><p>成功发送消息之后，我们再使用kafka的consumer 进行数据消费。</p><p>因为是用来测试手动提交</p><p>所以 将 enable.auto.commit 改成 false 进行手动提交</p><p>并且设置每次拉取最大10条</p><div class="language- vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span>props.put(&quot;enable.auto.commit&quot;, &quot;false&quot;);</span></span>
<span class="line"><span>props.put(&quot;max.poll.records&quot;, 10);</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>将提交方式改成false之后</p><p>需要手动提交只需加上这段代码</p><div class="language-angular2html vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">angular2html</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span>consumer.commitSync();</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>那么首先尝试消费不提交，测试能不能重复消费。</p><p>右键运行main方法进行消费，不提交offset下标。</p><p><img src="`+t+'" alt="img_7.png" loading="lazy"></p><p><img src="'+l+'" alt="img_8.png" loading="lazy"></p><p>成功消费之后，结束程序，再次运行main方法进行消费，也不提交offset下标。</p><p><img src="'+o+'" alt="img_9.png" loading="lazy"></p><p><img src="'+r+`" alt="img_10.png" loading="lazy"></p><p>并未手动进行提交，而且并未更改消费组名，但是可以看到已经重复消费了！</p><p>接下来，开始测试手动提交。</p><p>测试目的:</p><p>1.测试手动提交之后的offset，能不能再次消费。</p><p>2.测试未提交的offset，能不能再次进行消费。</p><p>测试方法: 当消费到50条的时候，进行手动提交，然后剩下的50条不进行提交。</p><p>希望达成的目的: 手动提交的offset不能再次消费，未提交的可以再次进行消费。</p><p>为了达到上述目的，我们测试只需添加如下代码即可:</p><div class="language- vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span>if(list.size()==50){</span></span>
<span class="line"><span>    consumer.commitSync();</span></span>
<span class="line"><span>}</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>更改代码之后，开始运行程序</p><p>测试示例图如下:</p><p><img src="`+c+'" alt="img_11.png" loading="lazy"></p><p><img src="'+m+`" alt="img_12.png" loading="lazy"></p><p>简单的一看，和之前未提交的一样，貌似没有什么问题。</p><blockquote><p>但是正常来说，未提交的下标不应该重复进行消费，直到它提交为止吗？</p></blockquote><p>因为要进行重复消费，但是messageNo 会一直累加，只会手动的提交前50条offset，</p><p>后面的50条offset会一直无法消费，所以打印的条数不应该是100，而是应该一直打印。</p><blockquote><p>那么测试的结果和预想的为什么不一致呢？</p></blockquote><p>之前不是已经测试过可以重复消费未提交的offset吗？</p><p>其实这点可以根据两次启动方式的不同而得出结论。</p><p>开始测试未提交重复消费的时候，实际我是启动-暂停-启动，那么本地的consumer实际是被初始化过两次。</p><p>而刚刚测试的实际consumer只有初始化一次。</p><blockquote><p>至于为什么初始化一次就不行呢？</p></blockquote><p>因为kafka的offset下标的记录实际会有两份，服务端会自己记录一份，本地的消费者客户端也会记录一份， 提交的offset会告诉服务端已经消费到这了，但是本地的并不会因此而改变offset进行再次消费。</p><p>简单的来说假如有10条数据，在第5条的时候进行提交了offset下标，那么服务端就知道该组消费的下标到第5条了， 如果同组其他的consumer进行消费的时候就会从第6条开始进行消费。但是本地的消费者客户端并不会因此而改变， 它还是会继续消费下去，并不会再次从第6条开始消费，所以会出现上图情况。</p><p>但是项目中运行之后，是不会因此而重启的，所以这时我们可以换一种思路。</p><p>就是如果触发某个条件，所以导致offset未提交，我们就可以关闭之前的consumer，然后新new一个consumer，这样就可以再次进行消费了！ 当然配置要和之前的一样。</p><p>那么将之前的提交代码更改如下:</p><div class="language-angular2html vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">angular2html</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span>if(list.size()==50){</span></span>
<span class="line"><span>    consumer.commitSync();</span></span>
<span class="line"><span>}else if(list.size()&gt;50){</span></span>
<span class="line"><span>    consumer.close();</span></span>
<span class="line"><span>    init();</span></span>
<span class="line"><span>    list.clear();</span></span>
<span class="line"><span>    list2.clear();</span></span>
<span class="line"><span>}</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><p>注:这里因为是测试，为了简单明了，所以条件我写的很简单。实际情况请根据个人的为准。</p><p><img src="`+u+'" alt="img_13.png" loading="lazy"></p><p><img src="'+g+'" alt="img_14.png" loading="lazy"></p><blockquote><p>说明:</p></blockquote><p>1.因为每次是拉取10条，所以在60条的时候kafka的配置初始化了，然后又从新拉取了50-60条的数据，但是没有提交，所以并不会影响实际结果。</p><p>2.这里为了方便截图展示，所以打印条件改了，但是不影响程序！</p><ul><li>从测试结果中，我们达到了之前想要测试的目的，未提交的offset可以重复进行消费。</li><li>这种做法一般也可以满足大部分需求。</li><li>例如从kafka获取数据入库，如果一批数据入库成功，就提交offset，否则不提交，然后再次拉取。</li><li>但是这种做法并不能最大的保证数据的完整性。比如在运行的时候，程序挂了之类的。</li></ul><p>所以还有一种方法是手动的指定offset下标进行获取数据，直到kafka的数据处理成功之后，将offset记录下来，比如写在数据库中。</p>',71),b=[f];function k(_,h,v,y,q,z){return p(),a("div",null,b)}const B=s(d,[["render",k]]);export{j as __pageData,B as default};
